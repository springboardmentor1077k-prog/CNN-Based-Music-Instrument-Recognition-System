{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7306ec76-f9d3-484b-a21c-05cdea216fe9",
   "metadata": {
    "id": "7306ec76-f9d3-484b-a21c-05cdea216fe9"
   },
   "source": [
    "## Step 1: Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5469e3-5e5c-4dc6-8650-6effbedd3df4",
   "metadata": {
    "id": "9d5469e3-5e5c-4dc6-8650-6effbedd3df4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122aaf9d-ae42-4db8-9b55-0cf05b74d678",
   "metadata": {
    "id": "122aaf9d-ae42-4db8-9b55-0cf05b74d678"
   },
   "source": [
    "## Step 2: Dataset Paths and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8aa399f-34ee-4211-b77e-0e9852392077",
   "metadata": {
    "id": "b8aa399f-34ee-4211-b77e-0e9852392077"
   },
   "outputs": [],
   "source": [
    "# IRMAS mono training data root\n",
    "DATASET_ROOT = r\"E:\\InstruNet-AI\\data\\IRMAS-TrainingData\"\n",
    "\n",
    "# Where we will store split file lists\n",
    "SPLIT_META_DIR = r\"E:\\InstruNet-AI\\data\\splits\"\n",
    "os.makedirs(SPLIT_META_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbfc7a-b5b7-4a1b-8786-dd5b843383c9",
   "metadata": {
    "id": "8bfbfc7a-b5b7-4a1b-8786-dd5b843383c9"
   },
   "source": [
    "## Step 3: Scan Dataset and Collect File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a675a247-b64e-4147-8372-ce5f26793627",
   "metadata": {
    "id": "a675a247-b64e-4147-8372-ce5f26793627",
    "outputId": "5bd2886b-dc4e-40bf-b4c6-ac4ce8f63c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mono samples found: 6705\n"
     ]
    }
   ],
   "source": [
    "data_index = []  # (file_path, class_name)\n",
    "\n",
    "for class_name in os.listdir(DATASET_ROOT):\n",
    "    class_dir = os.path.join(DATASET_ROOT, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.lower().endswith(\".wav\"):\n",
    "            file_path = os.path.join(class_dir, file)\n",
    "            data_index.append((file_path, class_name))\n",
    "\n",
    "print(f\"Total mono samples found: {len(data_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb375a1-21ae-4b77-bca8-9ae681beed9b",
   "metadata": {
    "id": "2cb375a1-21ae-4b77-bca8-9ae681beed9b"
   },
   "source": [
    "## Step 4: Encode Labels Numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f89627-0ecb-40df-9b5f-fea5d75f4887",
   "metadata": {
    "id": "d9f89627-0ecb-40df-9b5f-fea5d75f4887",
    "outputId": "a5c62d9e-75e9-41e3-b4e8-8bf6f4a609d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping:\n",
      "cel -> 0\n",
      "cla -> 1\n",
      "flu -> 2\n",
      "gac -> 3\n",
      "gel -> 4\n",
      "org -> 5\n",
      "pia -> 6\n",
      "sax -> 7\n",
      "tru -> 8\n",
      "vio -> 9\n",
      "voi -> 10\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted(list(set(label for _, label in data_index)))\n",
    "class_to_id = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "id_to_class = {idx: cls for cls, idx in class_to_id.items()}\n",
    "\n",
    "print(\"Class mapping:\")\n",
    "for k, v in class_to_id.items():\n",
    "    print(f\"{k} -> {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd64833-2205-457f-99a4-5aabacc142ae",
   "metadata": {
    "id": "9cd64833-2205-457f-99a4-5aabacc142ae"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(SPLIT_META_DIR, \"label_map.json\"), \"w\") as f:\n",
    "    json.dump(class_to_id, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf5d4d-55bb-4ff0-92ca-9ce20915e992",
   "metadata": {
    "id": "bddf5d4d-55bb-4ff0-92ca-9ce20915e992"
   },
   "source": [
    "## Step 5: Prepare Stratified Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd94eee-bc0c-425d-940f-499d6b74553c",
   "metadata": {
    "id": "3dd94eee-bc0c-425d-940f-499d6b74553c"
   },
   "outputs": [],
   "source": [
    "file_paths = [fp for fp, _ in data_index]\n",
    "labels = [class_to_id[label] for _, label in data_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a42f33-ef16-4d33-85e7-7e931e6f8275",
   "metadata": {
    "id": "48a42f33-ef16-4d33-85e7-7e931e6f8275"
   },
   "source": [
    "## Step 6: Train / Temp Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6957a28-2be2-4d1d-84f1-234bfa27e73f",
   "metadata": {
    "id": "e6957a28-2be2-4d1d-84f1-234bfa27e73f",
    "outputId": "6dd320da-a5e1-4a61-f8b7-feddf123c499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4693\n",
      "Temp size : 2012\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    file_paths,\n",
    "    labels,\n",
    "    test_size=(VAL_SIZE + TEST_SIZE),\n",
    "    stratify=labels,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Temp size : {len(X_temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7909a9b-6b9c-4779-9da0-99639b930d76",
   "metadata": {
    "id": "f7909a9b-6b9c-4779-9da0-99639b930d76"
   },
   "source": [
    "## Step 7: Validation / Test Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b86639-2b70-4cc8-9d17-231cb154de7b",
   "metadata": {
    "id": "e5b86639-2b70-4cc8-9d17-231cb154de7b",
    "outputId": "6e8f44b2-cd7c-46fe-fad3-ead71c981168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 1006\n",
      "Test size      : 1006\n"
     ]
    }
   ],
   "source": [
    "relative_test_size = TEST_SIZE / (VAL_SIZE + TEST_SIZE)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=relative_test_size,\n",
    "    stratify=y_temp,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Validation size: {len(X_val)}\")\n",
    "print(f\"Test size      : {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cac82-5eff-4c85-bffd-c1546f4a51a5",
   "metadata": {
    "id": "453cac82-5eff-4c85-bffd-c1546f4a51a5"
   },
   "source": [
    "## Step 8: Verify Class Distribution (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84853330-804a-4233-97da-c54c7a89828a",
   "metadata": {
    "id": "84853330-804a-4233-97da-c54c7a89828a",
    "outputId": "8fe023f7-0a30-4be0-824e-9eb8058c905c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      "{'cla': 353, 'pia': 505, 'gac': 446, 'org': 477, 'vio': 406, 'sax': 438, 'cel': 272, 'gel': 532, 'tru': 404, 'flu': 316, 'voi': 544}\n",
      "\n",
      "Validation distribution:\n",
      "{'vio': 87, 'gel': 114, 'tru': 87, 'pia': 108, 'voi': 117, 'flu': 67, 'org': 102, 'gac': 96, 'cel': 58, 'sax': 94, 'cla': 76}\n",
      "\n",
      "Test distribution:\n",
      "{'pia': 108, 'voi': 117, 'sax': 94, 'cel': 58, 'org': 103, 'vio': 87, 'cla': 76, 'gel': 114, 'tru': 86, 'gac': 95, 'flu': 68}\n"
     ]
    }
   ],
   "source": [
    "def count_classes(labels, id_to_class):\n",
    "    counts = defaultdict(int)\n",
    "    for y in labels:\n",
    "        counts[id_to_class[y]] += 1\n",
    "    return dict(counts)\n",
    "\n",
    "print(\"Train distribution:\")\n",
    "print(count_classes(y_train, id_to_class))\n",
    "\n",
    "print(\"\\nValidation distribution:\")\n",
    "print(count_classes(y_val, id_to_class))\n",
    "\n",
    "print(\"\\nTest distribution:\")\n",
    "print(count_classes(y_test, id_to_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eede5-4cb9-44da-986b-9dd8b6fba806",
   "metadata": {
    "id": "b50eede5-4cb9-44da-986b-9dd8b6fba806"
   },
   "source": [
    "## Step 9: Save Split Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041b798f-fc48-436b-a04d-e72e6a340b82",
   "metadata": {
    "id": "041b798f-fc48-436b-a04d-e72e6a340b82",
    "outputId": "c31cb133-75e9-4535-bed3-0ef0d8cbd237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "split_data = {\n",
    "    \"train\": X_train,\n",
    "    \"val\": X_val,\n",
    "    \"test\": X_test\n",
    "}\n",
    "\n",
    "with open(os.path.join(SPLIT_META_DIR, \"split_files.json\"), \"w\") as f:\n",
    "    json.dump(split_data, f, indent=2)\n",
    "\n",
    "print(\"Split metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ba68b-6a27-4603-b4ea-74fa6bbb74b0",
   "metadata": {
    "id": "427ba68b-6a27-4603-b4ea-74fa6bbb74b0"
   },
   "source": [
    "## Step 10: Load split metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fd49a3-40bf-4f98-ba0b-bbf5bb7bcf8f",
   "metadata": {
    "id": "85fd49a3-40bf-4f98-ba0b-bbf5bb7bcf8f"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc2c2b9-3547-401a-b5aa-83a2c14e6d1a",
   "metadata": {
    "id": "4fc2c2b9-3547-401a-b5aa-83a2c14e6d1a",
    "outputId": "4e39a6d7-28df-455a-bbe4-799ca98584c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test'])\n"
     ]
    }
   ],
   "source": [
    "SPLIT_META_PATH = r\"E:\\InstruNet-AI\\data\\splits\\split_files.json\"\n",
    "\n",
    "with open(SPLIT_META_PATH, \"r\") as f:\n",
    "    split_data = json.load(f)\n",
    "\n",
    "print(split_data.keys())  # train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c8cb1-308e-42e3-ad1f-a46bda83637f",
   "metadata": {
    "id": "9c3c8cb1-308e-42e3-ad1f-a46bda83637f"
   },
   "source": [
    "## Step 11: Define new dataset root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164675a7-d7b4-4251-9baa-ba93d4ddb3cd",
   "metadata": {
    "id": "164675a7-d7b4-4251-9baa-ba93d4ddb3cd"
   },
   "outputs": [],
   "source": [
    "NEW_DATASET_ROOT = r\"E:\\InstruNet-AI\\data\\irmas_mono\"\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(NEW_DATASET_ROOT, split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332f9a5-c3ef-4034-8a5c-ee3cc14bb8cf",
   "metadata": {
    "id": "a332f9a5-c3ef-4034-8a5c-ee3cc14bb8cf"
   },
   "source": [
    "## Step 12: Copy files into split folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2535dc-be7a-4d62-8e3e-00470b89347f",
   "metadata": {
    "id": "6e2535dc-be7a-4d62-8e3e-00470b89347f",
    "outputId": "acce58bb-09d1-41f9-c339-080d8ebd0660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: train\n",
      "Processing split: val\n",
      "Processing split: test\n"
     ]
    }
   ],
   "source": [
    "for split, file_list in split_data.items():\n",
    "    print(f\"Processing split: {split}\")\n",
    "\n",
    "    for file_path in file_list:\n",
    "        class_name = os.path.basename(os.path.dirname(file_path))\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        dest_dir = os.path.join(NEW_DATASET_ROOT, split, class_name)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "        dest_path = os.path.join(dest_dir, file_name)\n",
    "\n",
    "        # MOVE the file (use copy2 if you want a backup)\n",
    "        shutil.copy2(file_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82adeb-1652-4b2b-b204-1c5acd0550c3",
   "metadata": {
    "id": "de82adeb-1652-4b2b-b204-1c5acd0550c3"
   },
   "source": [
    "## Step 13: Verify the new structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bfeb19-d0ff-4ae9-9a45-3a4c7b0651cf",
   "metadata": {
    "id": "08bfeb19-d0ff-4ae9-9a45-3a4c7b0651cf",
    "outputId": "9b27da35-d938-4b3b-e428-04f8f800bd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN\n",
      "cel: 272\n",
      "cla: 353\n",
      "flu: 316\n",
      "gac: 446\n",
      "gel: 532\n",
      "org: 477\n",
      "pia: 505\n",
      "sax: 438\n",
      "tru: 404\n",
      "vio: 406\n",
      "voi: 544\n",
      "Total train: 4693\n",
      "\n",
      "VAL\n",
      "cel: 58\n",
      "cla: 76\n",
      "flu: 67\n",
      "gac: 96\n",
      "gel: 114\n",
      "org: 102\n",
      "pia: 108\n",
      "sax: 94\n",
      "tru: 87\n",
      "vio: 87\n",
      "voi: 117\n",
      "Total val: 1006\n",
      "\n",
      "TEST\n",
      "cel: 58\n",
      "cla: 76\n",
      "flu: 68\n",
      "gac: 95\n",
      "gel: 114\n",
      "org: 103\n",
      "pia: 108\n",
      "sax: 94\n",
      "tru: 86\n",
      "vio: 87\n",
      "voi: 117\n",
      "Total test: 1006\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_dir = os.path.join(NEW_DATASET_ROOT, split)\n",
    "    total = 0\n",
    "    print(f\"\\n{split.upper()}\")\n",
    "\n",
    "    for cls in os.listdir(split_dir):\n",
    "        cls_dir = os.path.join(split_dir, cls)\n",
    "        n = len([f for f in os.listdir(cls_dir) if f.endswith(\".wav\")])\n",
    "        total += n\n",
    "        print(f\"{cls}: {n}\")\n",
    "\n",
    "    print(f\"Total {split}: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9677a-3da5-4dcc-994a-ebd5378e16a0",
   "metadata": {
    "id": "3cb9677a-3da5-4dcc-994a-ebd5378e16a0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "InstruNet_venv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
