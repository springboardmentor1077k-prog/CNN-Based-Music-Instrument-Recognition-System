{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of multilabel trained model"
      ],
      "metadata": {
        "id": "P_9nmk3zHE8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zDYAMt_lGF80"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Paths & Parameters\n",
        "MODEL_PATH = \"/content/drive/MyDrive/irmas_multilabel_cnn.keras\"\n",
        "LABELS_CSV = \"/content/drive/MyDrive/multilabel_labels.csv\"\n",
        "MEL_DIR = \"/content/drive/MyDrive/irmas_multilabel_mels\"\n",
        "\n",
        "IMG_SIZE = 128"
      ],
      "metadata": {
        "id": "m7CySGccHRUI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Trained Model\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"✅ Model loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp-rCO6JHX98",
        "outputId": "15040431-e7a9-4236-def0-5ef8896cab57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset (Images + Labels)\n",
        "labels_df = pd.read_csv(LABELS_CSV)\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for _, row in labels_df.iterrows():\n",
        "    img_path = os.path.join(MEL_DIR, row[\"file\"].replace(\".wav\", \".png\"))\n",
        "    if not os.path.exists(img_path):\n",
        "        continue\n",
        "\n",
        "    img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    img = img_to_array(img) / 255.0\n",
        "\n",
        "    X.append(img)\n",
        "    y.append(row[1:].values.astype(\"float32\"))\n",
        "\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.float32)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiQguhSxHgRx",
        "outputId": "9b853b15-33aa-43fd-9bbe-cbb4fb4a859c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1000, 128, 128, 3)\n",
            "y shape: (1000, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train / Validation Split (for evaluation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "McUAno-DHogC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras Evaluation Metrics\n",
        "loss, binary_acc, precision, recall = model.evaluate(X_val, y_val)\n",
        "\n",
        "print(\"\\n=== KERAS EVALUATION ===\")\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Binary Accuracy:\", binary_acc)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHgvU4aMHsJk",
        "outputId": "23913df7-37e9-491b-8205-c41269cb66c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - binary_accuracy: 0.7825 - loss: 0.4984 - precision_2: 0.7238 - recall_2: 0.0417\n",
            "\n",
            "=== KERAS EVALUATION ===\n",
            "Loss: 0.5006890296936035\n",
            "Binary Accuracy: 0.7809090614318848\n",
            "Precision: 0.7083333134651184\n",
            "Recall: 0.03455284610390663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Threshold-based Evaluation (IMPORTANT for multilabel)\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "THRESHOLD = 0.3\n",
        "y_pred_bin = (y_pred >= THRESHOLD).astype(int)\n",
        "\n",
        "precision_t = precision_score(y_val, y_pred_bin, average=\"micro\")\n",
        "recall_t = recall_score(y_val, y_pred_bin, average=\"micro\")\n",
        "f1_t = f1_score(y_val, y_pred_bin, average=\"micro\")\n",
        "\n",
        "print(\"\\n=== THRESHOLD-BASED METRICS ===\")\n",
        "print(\"Threshold:\", THRESHOLD)\n",
        "print(\"Precision:\", precision_t)\n",
        "print(\"Recall:\", recall_t)\n",
        "print(\"F1-Score:\", f1_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVGCp43_Hw4y",
        "outputId": "b59ae67a-0335-4259-a88c-5f331170c8af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step\n",
            "\n",
            "=== THRESHOLD-BASED METRICS ===\n",
            "Threshold: 0.3\n",
            "Precision: 0.3582089552238806\n",
            "Recall: 0.43902439024390244\n",
            "F1-Score: 0.39452054794520547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test multiple thresholds:\n",
        "\n",
        "for t in [0.2, 0.3, 0.4, 0.5]:\n",
        "    y_bin = (y_pred >= t).astype(int)\n",
        "    f1 = f1_score(y_val, y_bin, average=\"micro\")\n",
        "    print(f\"Threshold {t} → F1: {f1:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exlyprQrIzCA",
        "outputId": "865386f8-ca8a-4d1b-ac03-83d688c314bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold 0.2 → F1: 0.421\n",
            "Threshold 0.3 → F1: 0.395\n",
            "Threshold 0.4 → F1: 0.204\n",
            "Threshold 0.5 → F1: 0.066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FINAL_THRESHOLD = 0.2\n",
        "FINAL_THRESHOLD = 0.2\n",
        "y_pred_bin = (y_pred >= FINAL_THRESHOLD).astype(int)\n",
        "\n",
        "precision = precision_score(y_val, y_pred_bin, average=\"micro\")\n",
        "recall = recall_score(y_val, y_pred_bin, average=\"micro\")\n",
        "f1 = f1_score(y_val, y_pred_bin, average=\"micro\")\n",
        "\n",
        "print(\"Final Threshold:\", FINAL_THRESHOLD)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwp5NC_CJVkw",
        "outputId": "19116f00-0034-4025-e72b-9c779e7fe8eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Threshold: 0.2\n",
            "Precision: 0.2796780684104628\n",
            "Recall: 0.8475609756097561\n",
            "F1-score: 0.4205748865355522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After threshold analysis, 0.2 was selected as the final decision threshold and used for reporting performance."
      ],
      "metadata": {
        "id": "8wkdPAJCKOsS"
      }
    }
  ]
}