{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvhxNZHe5m7o"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained multilabel model\n",
        "model = load_model(\"/content/drive/MyDrive/multilabel_cnn_improved.keras\")"
      ],
      "metadata": {
        "id": "s0Q64mkV6QeA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "# Audio parameters\n",
        "SR = 16000\n",
        "\n",
        "# Segmentation parameters\n",
        "SEGMENT_DURATION = 2.0   # seconds\n",
        "HOP_DURATION = 1.0       # seconds (50% overlap)\n",
        "\n",
        "SEGMENT_SAMPLES = int(SEGMENT_DURATION * SR)\n",
        "HOP_SAMPLES = int(HOP_DURATION * SR)\n",
        "\n",
        "# Spectrogram parameters\n",
        "N_MELS = 128\n",
        "HOP_LENGTH = 512\n",
        "IMG_SIZE = 128\n",
        "\n",
        "# Prediction threshold\n",
        "THRESHOLD = 0.5"
      ],
      "metadata": {
        "id": "UHJWVrHj7iRr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio Segmentation Function\n",
        "def segment_audio(audio, segment_samples, hop_samples):\n",
        "    segments = []\n",
        "    for start in range(0, len(audio) - segment_samples + 1, hop_samples):\n",
        "        seg = audio[start:start + segment_samples]\n",
        "        segments.append(seg)\n",
        "    return segments"
      ],
      "metadata": {
        "id": "w9vkRR2Noj6w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Segment â†’ Mel Spectrogram\n",
        "def segment_to_mel(segment, sr):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=segment,\n",
        "        sr=sr,\n",
        "        n_mels=N_MELS,\n",
        "        hop_length=HOP_LENGTH\n",
        "    )\n",
        "\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    mel_db = tf.image.resize(\n",
        "        mel_db[..., np.newaxis],\n",
        "        (IMG_SIZE, IMG_SIZE)\n",
        "    ).numpy()\n",
        "\n",
        "    mel_db = np.repeat(mel_db, 3, axis=-1)\n",
        "\n",
        "    mel_db = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-6)\n",
        "\n",
        "    return mel_db"
      ],
      "metadata": {
        "id": "kLtg3hWOoook"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Segment-wise Prediction (NO AGGREGATION)\n",
        "def predict_segments(audio_path):\n",
        "    audio, sr = librosa.load(audio_path, sr=SR, mono=True)\n",
        "\n",
        "    segments = segment_audio(audio, SEGMENT_SAMPLES, HOP_SAMPLES)\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for i, seg in enumerate(segments):\n",
        "        mel_img = segment_to_mel(seg, sr)\n",
        "        mel_img = np.expand_dims(mel_img, axis=0)\n",
        "\n",
        "        probs = model.predict(mel_img, verbose=0)[0]\n",
        "        preds = (probs >= THRESHOLD).astype(int)\n",
        "\n",
        "        predictions.append((i, probs, preds))\n",
        "\n",
        "    return segments, predictions"
      ],
      "metadata": {
        "id": "CS_LSUwsowuh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEMPORAL MAX POOLING (AGGREGATION)\n",
        "def temporal_max_pooling(predictions):\n",
        "    \"\"\"\n",
        "    Max pooling over segment probabilities\n",
        "    \"\"\"\n",
        "    segment_probs = np.array([probs for _, probs, _ in predictions])\n",
        "    pooled_probs = np.max(segment_probs, axis=0)\n",
        "    pooled_preds = (pooled_probs >= THRESHOLD).astype(int)\n",
        "    return pooled_probs, pooled_preds"
      ],
      "metadata": {
        "id": "ef1fcl1po6Af"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test audio\n",
        "TEST_AUDIO = \"/content/drive/MyDrive/irmas_multilabel_audio/mix_0.wav\""
      ],
      "metadata": {
        "id": "Ott_K-o9uGsb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN PIPELINE\n",
        "segments, predictions = predict_segments(TEST_AUDIO)\n",
        "# Print number of segments\n",
        "print(f\"\\nTotal segments: {len(predictions)}\")"
      ],
      "metadata": {
        "id": "qWIdYq40uN7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fe8756-9deb-46cc-b79f-b528075c3748"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total segments: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OUTPUT: WITHOUT AGGREGATION\n",
        "print(\"\\nWITHOUT AGGREGATION (Segment-wise predictions)\\n\")\n",
        "\n",
        "for i, probs, preds in predictions:\n",
        "    print(f\"Segment {i}\")\n",
        "    print(\"Probabilities:\", np.round(probs, 3))\n",
        "    print(\"Predicted labels:\", preds)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghpSU-mfuTYa",
        "outputId": "f273fb9e-9f41-48aa-be79-3e63b9f591b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WITHOUT AGGREGATION (Segment-wise predictions)\n",
            "\n",
            "Segment 0\n",
            "Probabilities: [0.041 0.057 0.072 0.029 0.073 0.019 0.052 0.474 0.752 0.082 0.011]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 1 0 0]\n",
            "--------------------------------------------------\n",
            "Segment 1\n",
            "Probabilities: [0.048 0.056 0.081 0.035 0.089 0.017 0.059 0.48  0.714 0.089 0.015]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 1 0 0]\n",
            "--------------------------------------------------\n",
            "Segment 2\n",
            "Probabilities: [0.059 0.141 0.12  0.071 0.043 0.055 0.112 0.431 0.866 0.13  0.014]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 1 0 0]\n",
            "--------------------------------------------------\n",
            "Segment 3\n",
            "Probabilities: [0.49  0.489 0.491 0.491 0.492 0.49  0.487 0.493 0.493 0.487 0.49 ]\n",
            "Predicted labels: [0 0 0 0 0 0 0 0 0 0 0]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OUTPUT: WITH MAX POOLING AGGREGATION\n",
        "agg_probs, agg_preds = temporal_max_pooling(predictions)\n",
        "\n",
        "print(\"\\nWITH TEMPORAL MAX POOLING (Clip-level prediction)\\n\")\n",
        "print(\"Aggregated probabilities:\", np.round(agg_probs, 3))\n",
        "print(\"Aggregated predicted labels:\", agg_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZfn6JnuXMs",
        "outputId": "1ce2c538-f682-41dc-9a2a-5eccebaaccda"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WITH TEMPORAL MAX POOLING (Clip-level prediction)\n",
            "\n",
            "Aggregated probabilities: [0.49  0.489 0.491 0.491 0.492 0.49  0.487 0.493 0.866 0.487 0.49 ]\n",
            "Aggregated predicted labels: [0 0 0 0 0 0 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REFLECTION (what changed, is it worth it?)\n",
        "print(\"\\n=== REFLECTION ===\")\n",
        "print(f\"Segment-level outputs before aggregation: {len(predictions)}\")\n",
        "print(\"Clip-level outputs after aggregation: 1\")\n",
        "\n",
        "if len(predictions) > 1:\n",
        "    print(\"Reflection: Aggregation is worthwhile as it converts multiple unstable segment predictions into a single stable clip-level decision.\")\n",
        "else:\n",
        "    print(\"Reflection: Aggregation has limited impact due to few segments.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whd1S6OHCPmV",
        "outputId": "baf9b39b-1630-4fae-b0fe-676e3ea9eb86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== REFLECTION ===\n",
            "Segment-level outputs before aggregation: 4\n",
            "Clip-level outputs after aggregation: 1\n",
            "Reflection: Aggregation is worthwhile as it converts multiple unstable segment predictions into a single stable clip-level decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "Applying temporal max pooling converted unstable segment-wise predictions into a single, stable clip-level output. Strong evidence from informative segments was preserved while weak or noisy segments did not suppress detection. This makes aggregation a worthwhile addition, improving robustness without retraining the model."
      ],
      "metadata": {
        "id": "CHRw4svzpcHc"
      }
    }
  ]
}