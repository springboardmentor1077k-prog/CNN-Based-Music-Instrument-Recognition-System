{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f68f96b-8dbc-4656-aecb-53edebc1306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 128, 128, 1) (6705,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load(\"X_mel.npy\")      # shape: (N, 128, 128, 1)\n",
    "y = np.load(\"y_labels.npy\")  # shape: (N,)\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a80b1e0-6500-4719-a0a0-f471def8a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srish\\anaconda3\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 11\n",
      "y shape: (6705, 11)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "y = to_categorical(y, num_classes)\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7a59e3-c149-4857-89c7-41658f528b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4693, 128, 128, 1)\n",
      "Val: (1006, 128, 128, 1)\n",
      "Test: (1006, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train (70%) + Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Validation (15%) + Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b0ea42-37a6-40fa-83af-e50f3c2b5b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.5685160427807487, 1: 1.2086015967035797, 2: 1.350115074798619, 3: 0.9565837749694251, 4: 0.801948051948052, 5: 0.8944158566800077, 6: 0.8448244824482448, 7: 0.9740556247405563, 8: 1.056030603060306, 9: 1.0508284818629645, 10: 0.7842580213903744}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train_labels),\n",
    "    y=y_train_labels\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31cc0e9-1a84-4b13-94e4-9079623d3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def spec_augment(mel, freq_mask=15, time_mask=20):\n",
    "    mel = mel.copy()\n",
    "\n",
    "    # Frequency masking\n",
    "    f = np.random.randint(0, freq_mask)\n",
    "    f0 = np.random.randint(0, mel.shape[0] - f)\n",
    "    mel[f0:f0 + f, :] = 0\n",
    "\n",
    "    # Time masking\n",
    "    t = np.random.randint(0, time_mask)\n",
    "    t0 = np.random.randint(0, mel.shape[1] - t)\n",
    "    mel[:, t0:t0 + t] = 0\n",
    "\n",
    "    return mel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0c516b-4e06-40f8-890e-ed045b97a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train: (4693, 128, 128, 1)\n",
      "Augmented train: (9386, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Remove channel dim → apply augment → add back\n",
    "X_train_aug = np.array([\n",
    "    spec_augment(x.squeeze()) for x in X_train\n",
    "])\n",
    "X_train_aug = X_train_aug[..., np.newaxis]\n",
    "\n",
    "# Combine original + augmented\n",
    "X_train_combined = np.concatenate([X_train, X_train_aug])\n",
    "y_train_combined = np.concatenate([y_train, y_train])\n",
    "\n",
    "print(\"Original train:\", X_train.shape)\n",
    "print(\"Augmented train:\", X_train_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c9f49-886a-4ca9-9fa3-520b562bcd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
