We will use 3 types of regularization:
1️ L2 weight regularization
2️ Dropout
3️ Batch Normalization

Note: Regularization techniques were incorporated into the CNN model to reduce overfitting and improve generalization. 
L2 weight regularization was applied to convolutional and dense layers, dropout was used in the fully connected layer, and batch normalization was added after convolutional layers. 
Early stopping and learning rate reduction callbacks were employed to further stabilize training.
